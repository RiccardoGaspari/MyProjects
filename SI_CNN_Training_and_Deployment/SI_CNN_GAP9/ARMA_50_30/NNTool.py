# coding: utf-8

# # MNist using NNTool python APIs

# In[ ]:


from nntool.api import NNGraph
from nntool.api.utils import RandomIter
from tqdm import tqdm
from glob import glob
from PIL import Image
import numpy as np

# Load the model in NNTool and apply static optimizations

# In[ ]:

path = '/home/rick/SI_CNN_GAP9/'

G = NNGraph.load_graph(path + 'ARMA_50_30_Bin_All.onnx')

G.adjust_order()
G.fusions("scaled_match_group")

G.draw()
print("Model before quantization")
print(G.show())


# ## Quantization
# In order to quantize the model we need to collect statistics on real samples

# In[ ]:

stats = G.collect_statistics(RandomIter.fake(G))


# Apply quantization options graph-wise and/or layer-wise.

# In[ ]:


G.quantize(
    stats,
    graph_options={
        "use_ne16": True,
        "hwc": True
    }
)

G.draw()
print("Model AFTER quantization")
print(G.show())

# this shows you instead of the shapes of each tensor, the quantization
G.draw(quant_labels=True)
# this shows you also the arithmetic quantization inside the expressions nodes
G.draw(expressions="quantized")
print("Quantization infos")

# for a more literal inspection
print(G.qshow())


# ## Test Accuracy
# After quantization the model is ready for deployment. Test accuracy of the deployable model and compare to the full precision accuracy.

# In[ ]:


# test_dataset = glob(TEST_DATASET)
def test_model(model, dataset, quant=True):
    correct = 0
    for img in tqdm(dataset):
        target = int(img.split("_")[-1].split(".")[0])
        img = Image.open(img)
        img = preprocessing(np.array(img).astype(np.float32))
        out = model.execute(img, dequantize=quant)
        pred = np.argmax(out[-1][0])
        correct += target == pred
    return correct * 100. / len(dataset)
    


# In[ ]:


# acc = test_model(G, test_dataset, False)
# print(f"Float32 accuracy: {acc:.2f}")
# acc = test_model(G, test_dataset, True)
# print(f"Int8  accuracy: {acc:.2f}")


# ## Run on target
# NNTool allows the user to directly get performance metrics of the platform directly from python APIs by generating a template project and run it.
# NOTE: the "gap9_project" was generated by this command, and then changed to adapt in a real application.

# In[ ]:


# Inference on a single image
test_img = np.random.rand(1, 20)
qout = G.execute(test_img, quantize=True, dequantize=False)
int_test = qout[0][0]

print(test_img.dtype)
print(test_img.shape)
print(int_test.dtype)
print(int_test.shape)


# In[ ]:


directory = "/tmp/mytest"
res = G.execute_on_target(
    directory=directory,
    input_tensors=int_test,
    write_out_to_file=True,
    print_output=True,
    check_on_target=True,
    settings={
        "l1_size": 128000,
        "l2_size": 1300000,
        "tensor_directory": "tensors",
        "model_directory": "model_dir"
    }
)

"""
G.gen_project(
    directory=path + "ARMA_50_30",
    input_tensors=int_test,
    # output_tensors=4, # 1: constants, 2: input, 4: output, (6 = 4|2: input+output, 7: all)
    # write_out_to_file=True,
    # print_output=True,
    # check_on_target=True,
    settings={
        "l1_size": 128000,
        "l2_size": 1300000,
        "tensor_directory": "tensors",
        "model_directory": "model_dir"
    },
    output_tensors=True
)
"""
# In[ ]:


print(res.stdout)


# In[ ]:


res.performance


# In[ ]:


out_gap = np.fromfile(directory + "/Output_1.bin", np.uint16)
print(f"Output from Target:\n{out_gap}")
print(f"Output from NNTool:\n{qout[-1][0]}")
if not np.allclose(out_gap, qout[-1][0]):
    raise ValueError("Outputs from NNTool and target are not the same")
else:
    print("Outputs from NNTool and target are the same")


